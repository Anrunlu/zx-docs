---
title: Python 线性回归
icon: fas fa-list
author: 周子力
order: 42
category:
  - 教学文档
tag:
  - Python
---
# Python 线性回归

## 1.什么是线性回归？

线性回归分析（Linear Regression Analysis)是确定两种或两种以上**变量间相互依赖的定量关系**的一种**统计分析方法**。本质上说，这种变量间依赖关系就是一种线性相关性，线性相关性是线性回归模型的理论基础

所以线性的定义是：**自变量之间只存在线性关系**，即自变量只能通过相加、或者相减进行组合

二十世纪二十年代，开创量子力学的哥本哈根学派科学家波尔、海森伯认则为认为世界上一切事物的发生都是不确定的，只能用概率也就是发生的可能性来描述事物运动规律。也就是说**世间一切的事儿都符合于某种概率分布而不是因果，可以用概率模型来表示一切规律**

**线性回归依然是工业界使用最广泛的模型**。和学校项目及Kaggle不同的是，工业界尤其是大一点的互联网公司，除了NLP和CV方向，一般缺的不是数据而是算力。同时因为数据量够多，线性回归这种简单的模型也可以产生不错的效果。而使用更复杂的模型不仅速度会大幅下降，准确率也不见得能提高多少。在很多场景下，因为公司没办法根据黑盒模型去做相应的策略，所以业务方也更需要可解释性的模型，如线性回归，决策树，知识图谱等。站在决策者的角度，他们也很难在重大问题上去相信无法解释的模型。所以线性回归，依旧是工业界使用最广泛，效果非常好的模型


![picture 0](https://oss.docs.z-xin.net/d17d4538632ba9e2780f198206c351ec1e8129f41d7fe2dea8aa9fda7b072556.png)  



## 2.线性模型的基本形式

![picture 1](https://oss.docs.z-xin.net/bee58a0c580525c24efe55ad7961bb9197df7873d2bce08eafd88d7a06395cc9.png)  


一般用向量形式可以写成：
$$
f(X)=W^TX+b
$$
为什么需要 b (Bias Parameter)：类似于线性函数中的截距，在线性模型中补偿了目标值的平均值（在训练集上的）于基函数值的加权平均值之间的差距。即打靶打歪了，但是允许通过平易**固定向量**的方式移动到目标点上（每个预测点和目标点之间的偏置都必须是固定的）

## 3.预测与真实间的距离

使用MSE（均方误差），求使D最小时的w,d
$$
D=E(f(x)-y)^2
$$

- SSE(误差平方和)
- 欧式距离
- 曼哈顿距离
- 马式距离
- 其他距离（汉明距离，编辑距离）

## 4.建立目标函数

这里使用均方误差MSE来判定距离，并限定损失函数为**平方损失函数，也就是普通最小二乘法（**Ordinary Least Square，OLS**）**，得到目标函数。其中“二乘”表示取平方，“最小”表示损失函数最小
$$
min\sum^n_{i=1}(y_i-f(x_i))^2
$$
通过调整参数使模型更加贴合真实数据
$$
(w^*,b^*)=argmin(w,b)\sum_{i=1}^n(y_i-wx_i-b)^2
$$
那么为什么用误差平方和来表示线性回归问题的损失函数？

这是因为线性回归有这样的假设，对于给定的 $ y^i $  总能找到$\varepsilon^{i}$ 使得这个等式成立  $y^i=h_\theta(x^i)+\varepsilon^i$，$\varepsilon^i$表示真实值和预测值之间的误差且服从正态分布$\varepsilon^i\sim N(0,\delta^2)$

为什么要加$\varepsilon$: 是因为建模的时候不可能把所有可能性都考虑。因此把剩下的特征及噪声统一放到一起来考虑。

**为什么误差要服从正态分布：** 误差的产生有很多种因素的影响，误差可以看作是这些因素(随机变量)之和共同作用而产生的，由中心极限定理可知随机变量和的分布近似的服从正态分布
随机变量$\varepsilon^i$的概率密度函数为：
$$
p(\varepsilon^i)=1\frac{1}{\sqrt{2\pi}\delta}e^{-\frac{(e^i)^2}{2\delta^2}}
$$
代入$\varepsilon^i=y^i-h_\theta(x^i)$ 则：
$$
p(y^i|x^i;\theta)=\frac{1}{\sqrt{2\pi}}e^{-\frac{(\theta^Tx^i-y^i)^2}{2\delta^2}}
$$































## 参考

https://zhuanlan.zhihu.com/p/147297924